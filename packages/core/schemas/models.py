"""Core data models for AIOS.

Enterprise-grade schemas supporting:
- Grounded AI with source attribution
- Authority tracking and provenance
- Decision lineage and auditability
"""

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any

from pydantic import BaseModel, Field


class HITLMode(str, Enum):
    """Human-in-the-loop modes."""

    INFORM = "INFORM"
    DRAFT = "DRAFT"
    EXECUTE = "EXECUTE"
    ESCALATE = "ESCALATE"


class AuthorityLevel(str, Enum):
    """Authority level for policies and decisions."""

    CONSTITUTIONAL = "constitutional"  # Highest - immutable core rules
    STATUTORY = "statutory"  # Legal/regulatory requirements
    ORGANIZATIONAL = "organizational"  # Organization-wide policies
    DEPARTMENTAL = "departmental"  # Department-specific rules
    OPERATIONAL = "operational"  # Day-to-day procedures


class SourceType(str, Enum):
    """Type of authoritative source."""

    POLICY = "policy"  # Internal policy document
    ORDINANCE = "ordinance"  # Legal ordinance/statute
    REGULATION = "regulation"  # Regulatory requirement
    PROCEDURE = "procedure"  # Standard operating procedure
    KNOWLEDGE_BASE = "knowledge_base"  # Uploaded knowledge document
    WEB_SOURCE = "web_source"  # Scraped web content
    HUMAN_INPUT = "human_input"  # Human-provided information


class VerificationStatus(str, Enum):
    """Verification status for sources and claims."""

    VERIFIED = "verified"  # Human-verified as accurate
    UNVERIFIED = "unverified"  # Not yet verified
    AI_GENERATED = "ai_generated"  # Generated by AI, not from sources
    REQUIRES_REVIEW = "requires_review"  # Flagged for human review
    DEPRECATED = "deprecated"  # Source is outdated


# =============================================================================
# GROUNDING SCHEMAS - Source Attribution & Authority Tracking
# =============================================================================


class SourceCitation(BaseModel):
    """A citation linking a claim to its authoritative source.

    This is the core of "grounded AI" - every claim should be traceable
    to a specific source with known authority.
    """

    source_id: str = Field(description="Unique identifier for the source")
    source_type: SourceType = Field(description="Type of authoritative source")
    source_name: str = Field(description="Human-readable source name")
    authority_level: AuthorityLevel = Field(
        default=AuthorityLevel.OPERATIONAL,
        description="Authority level of this source"
    )
    section_reference: str | None = Field(
        default=None,
        description="Specific section/clause reference (e.g., 'ยง4.2', 'Article III')"
    )
    quote: str | None = Field(
        default=None,
        description="Direct quote from source supporting the claim"
    )
    relevance_score: float = Field(
        default=1.0,
        ge=0.0,
        le=1.0,
        description="How relevant this source is to the claim"
    )
    verification_status: VerificationStatus = Field(
        default=VerificationStatus.UNVERIFIED,
        description="Verification status of this source"
    )
    last_verified_at: str | None = Field(
        default=None,
        description="When this source was last verified as current"
    )
    verified_by: str | None = Field(
        default=None,
        description="Who verified this source"
    )


class GroundedClaim(BaseModel):
    """A single claim/statement with its supporting evidence.

    Each substantive claim in a response should be traceable to sources.
    """

    claim_text: str = Field(description="The claim/statement being made")
    claim_index: int = Field(description="Position in the response (0-indexed)")
    citations: list[SourceCitation] = Field(
        default_factory=list,
        description="Sources supporting this claim"
    )
    confidence: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="Confidence in this claim based on source quality"
    )
    verification_status: VerificationStatus = Field(
        default=VerificationStatus.UNVERIFIED,
        description="Overall verification status of this claim"
    )
    requires_human_verification: bool = Field(
        default=False,
        description="Whether this claim needs human review"
    )


class ResponseGrounding(BaseModel):
    """Complete grounding metadata for a response.

    Answers the question: "What authoritative source justifies this output?"
    """

    claims: list[GroundedClaim] = Field(
        default_factory=list,
        description="List of claims with their supporting sources"
    )
    overall_grounding_score: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="Overall score of how well-grounded the response is"
    )
    primary_authority: AuthorityLevel = Field(
        default=AuthorityLevel.OPERATIONAL,
        description="Highest authority level cited in response"
    )
    ungrounded_claims: int = Field(
        default=0,
        description="Number of claims without source backing"
    )
    sources_used: int = Field(
        default=0,
        description="Total number of unique sources cited"
    )
    human_verified_claims: int = Field(
        default=0,
        description="Number of claims with human verification"
    )


# =============================================================================
# DECISION REASONING - Explainable Governance
# =============================================================================


class PolicyMatch(BaseModel):
    """Details of a policy rule that matched a query."""

    policy_id: str = Field(description="ID of the matched policy")
    policy_name: str = Field(description="Human-readable policy name")
    rule_condition: str = Field(description="The condition that triggered the match")
    match_reason: str = Field(description="Why this rule matched")
    authority_basis: str | None = Field(
        default=None,
        description="Legal/regulatory basis for this policy (e.g., 'HIPAA ยง164.502')"
    )
    priority: int = Field(default=0, description="Priority of this rule")


class DecisionReasoning(BaseModel):
    """Explanation of why a governance decision was made.

    Critical for auditability - shows the 'why' behind every decision.
    """

    matched_rules: list[PolicyMatch] = Field(
        default_factory=list,
        description="Rules that matched and influenced the decision"
    )
    reasoning_summary: str = Field(
        default="",
        description="Human-readable explanation of the decision"
    )
    alternatives_considered: list[dict[str, str]] = Field(
        default_factory=list,
        description="Other decisions considered and why rejected"
    )
    confidence: float = Field(
        default=1.0,
        ge=0.0,
        le=1.0,
        description="Confidence in this decision"
    )
    authority_chain: list[str] = Field(
        default_factory=list,
        description="Chain of authority for this decision (e.g., ['Constitutional', 'HR Policy 4.2'])"
    )


# =============================================================================
# RESPONSE LINEAGE - Full Traceability
# =============================================================================


class ResponseLineage(BaseModel):
    """Complete lineage tracking for a response.

    Enables full reconstruction of how a response was generated.
    """

    lineage_id: str = Field(description="Unique identifier for this lineage chain")
    request_id: str = Field(description="Original request ID")
    timestamp: str = Field(description="When this response was generated")

    # Query context
    original_query: str = Field(description="The user's original query")
    user_id: str = Field(description="Who made the query")
    user_role: str = Field(default="employee", description="User's role")
    user_department: str = Field(default="General", description="User's department")

    # Agent processing
    agent_id: str = Field(description="Which agent processed the query")
    agent_version: str = Field(default="1.0", description="Agent version at time of response")

    # Sources used
    sources_retrieved: list[dict[str, Any]] = Field(
        default_factory=list,
        description="All sources retrieved during processing"
    )
    sources_used_in_response: list[str] = Field(
        default_factory=list,
        description="Source IDs actually used in final response"
    )

    # Governance
    governance_decision: dict[str, Any] = Field(
        default_factory=dict,
        description="Full governance decision with reasoning"
    )
    guardrails_applied: list[str] = Field(
        default_factory=list,
        description="Guardrails that were enforced"
    )

    # Approval chain
    approval_required: bool = Field(default=False)
    approval_id: str | None = Field(default=None)
    approved_by: str | None = Field(default=None)
    approved_at: str | None = Field(default=None)
    approval_notes: str | None = Field(default=None)

    # Final response
    response_text: str = Field(description="The final response delivered")
    response_modified: bool = Field(
        default=False,
        description="Whether response was modified during approval"
    )
    original_response: str | None = Field(
        default=None,
        description="Original response before modification (if modified)"
    )

    # Attribution
    attribution: str = Field(
        default="ai_generated",
        description="'ai_generated', 'ai_assisted', 'human_authored'"
    )
    human_verified: bool = Field(
        default=False,
        description="Whether a human verified this response"
    )


# =============================================================================
# ENHANCED CORE MODELS
# =============================================================================


class Intent(BaseModel):
    """Classified intent from user request."""

    domain: str = Field(default="General", description="Domain category")
    task: str = Field(default="unknown", description="Specific task type")
    audience: str = Field(default="internal", description="Target audience")
    impact: str = Field(default="low", description="Impact level: low, medium, high")
    confidence: float = Field(default=0.0, ge=0.0, le=1.0, description="Classification confidence")


class RiskSignals(BaseModel):
    """Detected risk signals from user request."""

    signals: list[str] = Field(default_factory=list, description="List of risk signal codes")

    def contains(self, signal: str) -> bool:
        """Check if a specific risk signal is present."""
        return signal in self.signals


class UserContext(BaseModel):
    """User context for governance evaluation."""

    tenant_id: str = Field(description="Tenant/organization ID")
    user_id: str = Field(default="anonymous", description="User ID")
    role: str = Field(default="employee", description="User role")
    department: str = Field(default="General", description="User department")


class ProviderConstraints(BaseModel):
    """Constraints on which AI providers can be used."""

    local_only: bool = Field(default=False, description="Must use local LLM only")
    allowed_providers: list[str] = Field(default_factory=list, description="Allowed provider IDs")
    blocked_providers: list[str] = Field(default_factory=list, description="Blocked provider IDs")


class GovernanceDecision(BaseModel):
    """Result of governance policy evaluation.

    Enhanced with decision reasoning for full auditability.
    Answers: "Why was this decision made and by what authority?"
    """

    hitl_mode: HITLMode = Field(default=HITLMode.INFORM, description="Human-in-the-loop mode")
    tools_allowed: bool = Field(default=True, description="Whether tools can be executed")
    approval_required: bool = Field(default=False, description="Whether approval is required")
    escalation_reason: str | None = Field(default=None, description="Reason for escalation")
    policy_trigger_ids: list[str] = Field(default_factory=list, description="IDs of triggered policies")
    provider_constraints: ProviderConstraints = Field(
        default_factory=ProviderConstraints, description="Provider constraints"
    )

    # === NEW: Decision Reasoning (Grounded AI) ===
    reasoning: DecisionReasoning | None = Field(
        default=None,
        description="Detailed reasoning for this decision"
    )
    authority_basis: str | None = Field(
        default=None,
        description="Primary authority backing this decision (e.g., 'HIPAA ยง164.502', 'City Ordinance 12.4')"
    )
    confidence: float = Field(
        default=1.0,
        ge=0.0,
        le=1.0,
        description="Confidence in this governance decision"
    )


class GroundedResponse(BaseModel):
    """A fully grounded AI response with complete attribution.

    This is the enterprise-grade response format that answers:
    - What is the response? (response_text)
    - What sources justify it? (grounding)
    - Why was it allowed? (governance_decision)
    - Who approved it? (lineage)
    - Can we trust it? (verification_status)
    """

    response_text: str = Field(description="The actual response content")
    grounding: ResponseGrounding = Field(
        default_factory=ResponseGrounding,
        description="Source attribution and grounding metadata"
    )
    governance_decision: GovernanceDecision = Field(
        default_factory=GovernanceDecision,
        description="Governance decision with reasoning"
    )
    lineage: ResponseLineage | None = Field(
        default=None,
        description="Full response lineage for audit"
    )

    # Summary fields for quick access
    verification_status: VerificationStatus = Field(
        default=VerificationStatus.AI_GENERATED,
        description="Overall verification status"
    )
    grounding_score: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="How well-grounded is this response (0=speculation, 1=fully cited)"
    )
    requires_human_review: bool = Field(
        default=False,
        description="Whether this response needs human verification"
    )
    attribution: str = Field(
        default="ai_generated",
        description="'ai_generated', 'ai_assisted', 'human_authored', 'human_verified'"
    )
